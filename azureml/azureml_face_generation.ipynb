{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "If you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, you have to install the Azure Machine Learning Python SDK and create an Azure ML Workspace first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "\n",
    "print(\"Azure SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize workspace\n",
    "\n",
    "Initialize a [Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) object from the existing workspace you created in the Prerequisites step. Workspace.from_config() creates a workspace object from the details stored in config.json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create or Attach existing AmlCompute\n",
    "\n",
    "**Creation of AmlCompute takes approximately 5 minutes.** If the AmlCompute with that name is already in your workspace, this code will skip the creation process.\n",
    "\n",
    "As with other Azure services, there are limits on certain resources (e.g. AmlCompute) associated with the Azure Machine Learning service. Please read [this article](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-manage-quotas) on the default limits and how to request more quota."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# choose a name for your cluster\n",
    "cluster_name = \"gpu-cluster\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size='Standard_NC6', \n",
    "        vm_priority=\"dedicated\",\n",
    "        min_nodes = 0,\n",
    "        max_nodes = 12,\n",
    "        idle_seconds_before_scaledown=300\n",
    "    )\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "# can poll for a minimum number of nodes and for a specific timeout. \n",
    "# if no min node count is provided it uses the scale settings for the cluster\n",
    "compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "# use get_status() to get a detailed status for the current cluster. \n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model on the remote compute\n",
    "\n",
    "I need to setup my training environment with the following steps\n",
    "- Create a project directory & add training assets like scripts and data\n",
    "- Create an Azure ML experiment\n",
    "- Create an environment\n",
    "- Configure & submit the training job\n",
    "\n",
    "### Create a project directory & add training assets\n",
    "\n",
    "Create a directory that will contain all the necessary code from your local machine that you will need access to on the remote resource. This includes the training script and any additional files your training script depends on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "project_folder = './train'\n",
    "os.makedirs(project_folder, exist_ok=True)\n",
    "\n",
    "for script in glob.glob('../*.py'):\n",
    "    shutil.copy(script, project_folder)\n",
    "    \n",
    "for script in glob.glob('*.py'):\n",
    "    shutil.copy(script, project_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an experiment\n",
    "Create an Experiment to track all the runs in your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = 'face-generation'\n",
    "experiment = Experiment(ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an environment\n",
    "\n",
    "Define a conda environment YAML file with your training script dependencies and create an Azure ML environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile conda_dependencies.yml\n",
    "\n",
    "channels:\n",
    "- conda-forge\n",
    "dependencies:\n",
    "- python=3.6.2\n",
    "- pip:\n",
    "  - azureml-defaults\n",
    "  - torch==1.6.0\n",
    "  - torchvision==0.7.0\n",
    "  - future==0.17.1\n",
    "  - matplotlib==3.3.4\n",
    "  - torchsummary\n",
    "  - torchsummaryX\n",
    "  - pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "\n",
    "pytorch_env = Environment.from_conda_specification(name = 'pytorch-1.6-gpu', file_path = './conda_dependencies.yml')\n",
    "\n",
    "# Specify a GPU base image\n",
    "#pytorch_env.docker.enabled = True\n",
    "pytorch_env.docker.base_image = 'mcr.microsoft.com/azureml/openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the training job\n",
    "Create a ScriptRunConfig object to specify the configuration details of your training job, including your training script, environment to use, and the compute target to run on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "from azureml.core.runconfig import DockerConfiguration\n",
    "\n",
    "args = [\n",
    "    '--num_epochs', 20, \n",
    "    '--batch_size', 256,\n",
    "    '--img_size', 32,\n",
    "    '--d_conv_dim', 64,\n",
    "    '--g_conv_dim', 64,\n",
    "    '--z_size', 100,\n",
    "    '--learning_rate', 0.0002,\n",
    "    '--beta1', 0.5,\n",
    "    '--beta2', 0.999,\n",
    "    '--dataset_name', 'processed_celeba_small'\n",
    "]\n",
    "\n",
    "docker_config = DockerConfiguration(use_docker=True)\n",
    "script_run_config = ScriptRunConfig(source_directory=project_folder,\n",
    "                                    script='train.py',\n",
    "                                    arguments=args,\n",
    "                                    compute_target=compute_target,\n",
    "                                    environment=pytorch_env,\n",
    "                                    docker_runtime_config=docker_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit job\n",
    "Run your experiment by submitting your ScriptRunConfig object. Note that this call is asynchronous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_run = experiment.submit(script_run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor your run\n",
    "You can monitor the progress of the run with a Jupyter widget. Like the run submission, the widget is asynchronous and provides live updates every 10-15 seconds until the job completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(test_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can block until the script has completed training before running more code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = [\n",
    "    '--num_epochs', 20, \n",
    "    '--batch_size', 256,\n",
    "    '--img_size', 32,\n",
    "    '--d_conv_dim', 32,\n",
    "    '--g_conv_dim', 32,\n",
    "    '--z_size', 100,\n",
    "    '--learning_rate', 0.0002,\n",
    "    '--beta1', 0.5,\n",
    "    '--beta2', 0.999,\n",
    "    '--dataset_name', 'processed_celeba_small'\n",
    "]\n",
    "\n",
    "docker_config = DockerConfiguration(use_docker=True)\n",
    "script_run_config = ScriptRunConfig(source_directory=project_folder,\n",
    "                                    script='train.py',\n",
    "                                    arguments=args,\n",
    "                                    compute_target=compute_target,\n",
    "                                    environment=pytorch_env,\n",
    "                                    docker_runtime_config=docker_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_run2 = experiment.submit(script_run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(test_run).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
